{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a527da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### FIRST 5 ROWS OF DATA:\n",
      "         Age        Income  Purchase\n",
      "0  35.030791  15231.706200         1\n",
      "1  48.508547  20961.859939         1\n",
      "2  46.804709  20034.295842         1\n",
      "3  23.278116  23736.513334         1\n",
      "4  47.875280  20665.025504         1\n",
      "\n",
      "Model training complete.\n",
      "\n",
      "========================\n",
      "ðŸ“Œ MODEL LEARNED VALUES\n",
      "========================\n",
      "Intercept (baseline): -9.4647\n",
      "Meaning: This is the modelâ€™s starting point BEFORE adding age or income.\n",
      "\n",
      "Coefficient for AGE: -0.0518\n",
      "Meaning: For every +1 year increase in age, the log-odds of buying change by this amount.\n",
      "\n",
      "Coefficient for INCOME: 0.000685\n",
      "Meaning: For every 1 AED increase in income, the chance of buying changes by this small amount.\n",
      "ðŸ’¡ Higher income usually shifts prediction toward buying.\n",
      "\n",
      "Interpretation:\n",
      "Prediction = intercept + (coef_age * Age) + (coef_income * Income)\n",
      "Then logistic function converts this number into a probability between 0 and 1.\n",
      "\n",
      "============================\n",
      "ðŸ“Œ EXAMPLE PREDICTION\n",
      "============================\n",
      "Person: Age=30, Income=8000\n",
      "Predicted class (0=no buy, 1=buy): 1\n",
      "Predicted probabilities [no-buy, buy]: [4.00346423e-13 1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ================================================================\n",
    "# 1) MAKE FAKE CLASSIFICATION DATA (INTO 2 FEATURES AND A LABEL)\n",
    "# ================================================================\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=2,        # 2 features â†’ we will call them Age & Income\n",
    "    n_informative=2,\n",
    "    n_redundant=0,\n",
    "    n_classes=2,         # 0 = No Purchase, 1 = Purchase\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ================================================================\n",
    "# 2) CONVERT FEATURE 0 â†’ REALISTIC AGE (18â€“65)\n",
    "# ================================================================\n",
    "age_min, age_max = 18, 65\n",
    "\n",
    "x0 = X[:, 0]\n",
    "x0_norm = (x0 - x0.min()) / (x0.max() - x0.min())  # Normalize 0 â†’ 1\n",
    "\n",
    "age = x0_norm * (age_max - age_min) + age_min\n",
    "\n",
    "# ================================================================\n",
    "# 3) CONVERT FEATURE 1 â†’ REALISTIC INCOME (3000â€“30000)\n",
    "# ================================================================\n",
    "inc_min, inc_max = 3000, 30000\n",
    "\n",
    "x1 = X[:, 1]\n",
    "x1_norm = (x1 - x1.min()) / (x1.max() - x1.min())\n",
    "\n",
    "income = x1_norm * (inc_max - inc_min) + inc_min\n",
    "\n",
    "# ================================================================\n",
    "# 4) COMBINE BACK INTO NEW X WITH REALISTIC VALUES\n",
    "# ================================================================\n",
    "X_real = np.column_stack((age, income))\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Age\": age,\n",
    "    \"Income\": income,\n",
    "    \"Purchase\": y\n",
    "})\n",
    "\n",
    "print(\"\\n### FIRST 5 ROWS OF DATA:\")\n",
    "print(df.head())\n",
    "\n",
    "# ================================================================\n",
    "# 5) TRAIN / TEST SPLIT USING REALISTIC FEATURES\n",
    "# ================================================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_real, y, test_size=0.2, random_state=30\n",
    ")\n",
    "\n",
    "# ================================================================\n",
    "# 6) TRAIN LOGISTIC REGRESSION\n",
    "# ================================================================\n",
    "model = LogisticRegression(random_state=30)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nModel training complete.\")\n",
    "\n",
    "# ================================================================\n",
    "# 7) PRINT INTERCEPT & COEFFICIENTS (TEACHING EXPLANATION)\n",
    "# ================================================================\n",
    "\n",
    "intercept = model.intercept_[0]\n",
    "coef_age = model.coef_[0][0]\n",
    "coef_income = model.coef_[0][1]\n",
    "\n",
    "print(\"\\n========================\")\n",
    "print(\"ðŸ“Œ MODEL LEARNED VALUES\")\n",
    "print(\"========================\")\n",
    "\n",
    "print(f\"Intercept (baseline): {intercept:.4f}\")\n",
    "print(\"Meaning: This is the modelâ€™s starting point BEFORE adding age or income.\")\n",
    "\n",
    "print(f\"\\nCoefficient for AGE: {coef_age:.4f}\")\n",
    "print(\"Meaning: For every +1 year increase in age, the log-odds of buying change by this amount.\")\n",
    "\n",
    "print(f\"\\nCoefficient for INCOME: {coef_income:.6f}\")\n",
    "print(\"Meaning: For every 1 AED increase in income, the chance of buying changes by this small amount.\")\n",
    "print(\"ðŸ’¡ Higher income usually shifts prediction toward buying.\")\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"Prediction = intercept + (coef_age * Age) + (coef_income * Income)\")\n",
    "print(\"Then logistic function converts this number into a probability between 0 and 1.\")\n",
    "\n",
    "# ================================================================\n",
    "# 8) TEST AN EXAMPLE PERSON\n",
    "# ================================================================\n",
    "example = [[60, 60000]]  # Age 30, income 8000\n",
    "pred = model.predict(example)\n",
    "prob = model.predict_proba(example)\n",
    "\n",
    "print(\"\\n============================\")\n",
    "print(\"ðŸ“Œ EXAMPLE PREDICTION\")\n",
    "print(\"============================\")\n",
    "print(f\"Person: Age=30, Income=8000\")\n",
    "print(f\"Predicted class (0=no buy, 1=buy): {pred[0]}\")\n",
    "print(f\"Predicted probabilities [no-buy, buy]: {prob[0]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
