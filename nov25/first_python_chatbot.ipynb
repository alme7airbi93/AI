{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Decoding-Data-Science/nov25/blob/main/first_python_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek3Wj9p-s8P0",
        "outputId": "01a43e21-6b2c-495e-97af-68bcb0173448"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.8.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n"
          ]
        }
      ],
      "source": [
        "# pip install openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNsynaFotIn3"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()  # <-- THIS loads the .env file automatically\n",
        "\n",
        "\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQYc8vWHtQP2",
        "outputId": "b244e27e-065f-454c-93b5-3919d15ad898"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chatbot ready. Type 'exit' to stop.\n",
            "Bot: Got it! I confirm that I understand the requirements—you want an intelligent Python chatbot that maintains conversational context, reasons about user intent, asks clarifying questions when needed, and provides helpful, accurate, and natural-sounding responses without overstepping or hallucinating. Would you like me to start outlining the chatbot’s Python implementation next?\n",
            "Bot: Confirmed. I fully understand and acknowledge the specifications and behavior expected for the intelligent Python chatbot. Would you like me to proceed with writing or explaining the Python implementation now?\n",
            "Bot: Confirmed. Everything you’ve outlined for the chatbot is clear and understood. Would you like me to move forward with creating the actual Python code now?\n",
            "Bot: Confirmed. I completely understand the requirements and am ready to proceed whenever you are. Would you like me to generate the chatbot’s implementation next?\n",
            "Bot: Confirmed. All instructions and expectations are fully understood. Would you like me to begin implementing or demonstrating the chatbot’s design now?\n",
            "Bot: Sure! Here’s a simple Python loop example that stops after reaching 1000 iterations:  \n",
            "\n",
            "```python\n",
            "for i in range(1000):\n",
            "    print(i)\n",
            "```\n",
            "\n",
            "This loop runs from 0 up to 999 and then exits automatically once it reaches 1000 iterations. Would you like the loop to perform a specific action before it exits?\n",
            "Bot: If by “escape” you mean you want the loop to stop or break once it reaches 1000, you can do it with a `while` loop and a `break` statement like this:  \n",
            "\n",
            "```python\n",
            "i = 0\n",
            "while True:\n",
            "    if i == 1000:\n",
            "        break\n",
            "    print(i)\n",
            "    i += 1\n",
            "```\n",
            "\n",
            "This runs continuously until `i` equals 1000, at which point it exits cleanly. Would you like me to modify it so it stops under a different condition (like user input or an error)?\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\"Create an intelligent Python chatbot capable of engaging in natural, helpful, and contextually appropriate conversations with human users.\n",
        "\n",
        "Requirements:\n",
        "- Maintain conversational context over multiple user turns.\n",
        "- Respond helpfully and accurately to a wide range of user inputs.\n",
        "- Reason about user intent before generating each response.\n",
        "- Politely ask clarifying questions if a request is ambiguous or unclear.\n",
        "- Avoid hallucination or speculation—respond only with information you can justify or infer from context.\n",
        "- If unable to answer, politely acknowledge the limitation.\n",
        "\n",
        "Process:\n",
        "1. On each user message, first analyze prior context (if any) and what the user is likely asking/intending.\n",
        "2. Think step-by-step (chain-of-thought) to determine the most relevant, helpful response. Always reason internally before presenting your answer.\n",
        "3. If more information is needed, ask targeted clarifying questions.\n",
        "4. Output your response, maintaining natural tone and conversational flow.\n",
        "5. Continue the conversation until the user indicates they are finished.\n",
        "\n",
        "Output:\n",
        "- Each response should be in plain English, no markdown or code blocks unless explicitly requested.\n",
        "- Maintain a single-paragraph, natural-sounding chat response of 1–3 sentences (unless a longer reply is requested or required).\n",
        "\n",
        "Example—Instructions:\n",
        "- Reasoning: \"Recognize the user asked for Python list examples and may want to know how lists work.\"\n",
        "- Conclusion/Output: \"Sure! In Python, a list is a collection of items in a particular order. For example: my_list = [1, 2, 3, 4]. Would you like to see how to add or remove items?\"\n",
        "\n",
        "(For more advanced technical requests, reasoning steps and explanations may be slightly longer, but always conclude with a concise, clear reply to the user.)\n",
        "\n",
        "Edge Cases & Important Considerations:\n",
        "- If the user refers to prior conversation context, recall and incorporate it.\n",
        "- Be warm, engaging, and never condescending.\n",
        "- If asked for code, provide only what is needed and explain concisely.\n",
        "\n",
        "REMINDER: Your primary objective is to serve as a helpful Python chatbot, reasoning about context before each response, and outputting clear, appropriate conversational replies.\n",
        "\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"input_text\", \"text\": SYSTEM_PROMPT}\n",
        "        ],\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"Chatbot ready. Type 'exit' to stop.\")\n",
        "\n",
        "while True:\n",
        "    user_text = input(\"You: \").strip()\n",
        "    if not user_text:\n",
        "        continue\n",
        "    if user_text.lower() in {\"exit\", \"quit\", \"bye\"}:\n",
        "        print(\"Bot: Goodbye!\")\n",
        "        break\n",
        "\n",
        "    # Add user message\n",
        "    messages.append(\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"input_text\", \"text\": user_text}\n",
        "            ],\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Call the Responses API\n",
        "    response = client.responses.create(\n",
        "        model=\"gpt-5-chat-latest\",\n",
        "        input=messages,\n",
        "        text={\"format\": {\"type\": \"text\"}},\n",
        "        reasoning={},\n",
        "        tools=[],\n",
        "        temperature=1,\n",
        "        max_output_tokens=2048,\n",
        "        top_p=1,\n",
        "        store=True,\n",
        "        include=[\"web_search_call.action.sources\"]\n",
        "    )\n",
        "\n",
        "    assistant_text = response.output_text\n",
        "\n",
        "    print(\"Bot:\", assistant_text)\n",
        "\n",
        "    # Store assistant message to preserve context\n",
        "    messages.append(\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"output_text\", \"text\": assistant_text}\n",
        "            ],\n",
        "        }\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVxgRsVcv9x9",
        "outputId": "e8c7f308-6c67-4dc9-974e-30d10c738e21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.12.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.118.3)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.14.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<=2.12.3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.12.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.7)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "# pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "Pc8GucSCwGqs",
        "outputId": "0574c96f-00b0-4bc6-e6f4-7f91fc349b4d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\almehairbi\\Desktop\\Dell AI\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "C:\\Users\\almehairbi\\AppData\\Local\\Temp\\ipykernel_8380\\2225227705.py:91: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(height=420)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "* To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\"Create an intelligent Python chatbot capable of engaging in natural, helpful, and contextually appropriate conversations with human users.\n",
        "\n",
        "Requirements:\n",
        "- Maintain conversational context over multiple user turns.\n",
        "- Respond helpfully and accurately to a wide range of user inputs.\n",
        "- Reason about user intent before generating each response.\n",
        "- Politely ask clarifying questions if a request is ambiguous or unclear.\n",
        "- Avoid hallucination or speculation—respond only with information you can justify or infer from context.\n",
        "- If unable to answer, politely acknowledge the limitation.\n",
        "\n",
        "Process:\n",
        "1. On each user message, first analyze prior context (if any) and what the user is likely asking/intending.\n",
        "2. Think step-by-step (chain-of-thought) to determine the most relevant, helpful response. Always reason internally before presenting your answer.\n",
        "3. If more information is needed, ask targeted clarifying questions.\n",
        "4. Output your response, maintaining natural tone and conversational flow.\n",
        "5. Continue the conversation until the user indicates they are finished.\n",
        "\n",
        "Output:\n",
        "- Each response should be in plain English, no markdown or code blocks unless explicitly requested.\n",
        "- Maintain a single-paragraph, natural-sounding chat response of 1–3 sentences (unless a longer reply is requested or required).\n",
        "\n",
        "Example—Instructions:\n",
        "- Reasoning: \"Recognize the user asked for Python list examples and may want to know how lists work.\"\n",
        "- Conclusion/Output: \"Sure! In Python, a list is a collection of items in a particular order. For example: my_list = [1, 2, 3, 4]. Would you like to see how to add or remove items?\"\n",
        "\n",
        "(For more advanced technical requests, reasoning steps and explanations may be slightly longer, but always conclude with a concise, clear reply to the user.)\n",
        "\n",
        "Edge Cases & Important Considerations:\n",
        "- If the user refers to prior conversation context, recall and incorporate it.\n",
        "- Be warm, engaging, and never condescending.\n",
        "- If asked for code, provide only what is needed and explain concisely.\n",
        "\n",
        "REMINDER: Your primary objective is to serve as a helpful Python chatbot, reasoning about context before each response, and outputting clear, appropriate conversational replies.\n",
        "\"\"\"\n",
        "\n",
        "def init_messages():\n",
        "    return [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": [{\"type\": \"input_text\", \"text\": SYSTEM_PROMPT}]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "def respond(user_text, chat_history, messages):\n",
        "    if messages is None:\n",
        "        messages = init_messages()\n",
        "\n",
        "    # add user turn\n",
        "    messages.append(\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [{\"type\": \"input_text\", \"text\": user_text}]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # call API\n",
        "    response = client.responses.create(\n",
        "        model=\"gpt-5-chat-latest\",\n",
        "        input=messages,\n",
        "        text={\"format\": {\"type\": \"text\"}},\n",
        "        reasoning={},\n",
        "        tools=[],\n",
        "        temperature=1,\n",
        "        max_output_tokens=2048,\n",
        "        top_p=1,\n",
        "        store=True\n",
        "    )\n",
        "\n",
        "    assistant_text = response.output_text\n",
        "\n",
        "    # add assistant turn\n",
        "    messages.append(\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": [{\"type\": \"output_text\", \"text\": assistant_text}]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # update UI chat history\n",
        "    chat_history = chat_history + [(user_text, assistant_text)]\n",
        "\n",
        "    return \"\", chat_history, messages\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Python Chatbot (OpenAI Responses API)\")\n",
        "\n",
        "    chatbot = gr.Chatbot(height=420)\n",
        "    msg = gr.Textbox(placeholder=\"Type your Python question and press Enter\")\n",
        "    clear = gr.Button(\"Clear\")\n",
        "\n",
        "    state = gr.State(init_messages())\n",
        "\n",
        "    msg.submit(\n",
        "        respond,\n",
        "        inputs=[msg, chatbot, state],\n",
        "        outputs=[msg, chatbot, state]\n",
        "    )\n",
        "\n",
        "    clear.click(\n",
        "        fn=lambda: ([], init_messages()),\n",
        "        inputs=None,\n",
        "        outputs=[chatbot, state]\n",
        "    )\n",
        "\n",
        "demo.launch(debug=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNV/RiTOuOqEl6cPjcrj8mF",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
