{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Decoding-Data-Science/nov25/blob/main/random_for.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xf68XDUsd7Eq",
        "outputId": "2552a757-672d-40c3-c8d4-cb56bab20033"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- SYNTHETIC DATA CREATED ---\n",
            "Total instances: 1000\n",
            "Failure instances (1): 22\n",
            "------------------------------\n",
            "Model Training Status: COMPLETE\n",
            "Accuracy on Test Data: 0.9933 (The sources show high accuracy, around 95%, is typical for these models [6])\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries. Scikit-learn is essential for the Random Forest model [2].\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# --- STEP 1: MAKE UP SOME FAKE SENSOR DATA --- [1]\n",
        "# Create 1000 data points (simulating 1000 instances of sensor readings)\n",
        "N_SAMPLES = 1000\n",
        "\n",
        "# Create realistic-looking data for temperature and vibration, which are common sensor readings [3].\n",
        "# Temperature readings (e.g., centered around 70)\n",
        "temperature = np.random.normal(loc=70, scale=8, size=N_SAMPLES)\n",
        "# Vibration readings (e.g., centered around 5)\n",
        "vibration = np.random.normal(loc=5, scale=2, size=N_SAMPLES)\n",
        "# Pressure readings (as a potentially noisy, less predictive feature) [3]\n",
        "pressure = np.random.normal(loc=100, scale=10, size=N_SAMPLES)\n",
        "\n",
        "# Combine the data into a DataFrame for easier handling\n",
        "data = pd.DataFrame({\n",
        "    'Temperature': temperature,\n",
        "    'Vibration': vibration,\n",
        "    'Pressure': pressure\n",
        "})\n",
        "\n",
        "# --- STEP 2: CREATE A SIMPLE RULE FOR FAILURE (THE 'FINGERPRINT') --- [1, 2]\n",
        "# A failure that is about to happen leaves a fingerprint or pattern in the data [3].\n",
        "# We define a failure based on the rule: High Temp (e.g., > 80) AND High Vibration (e.g., > 7) [1, 2].\n",
        "\n",
        "# Initialize the target variable (0 = No Failure, 1 = Failure)\n",
        "data['Failure_Indicator'] = 0\n",
        "\n",
        "# Apply the failure rule: If both conditions are met, set the indicator to 1.\n",
        "failure_condition = (data['Temperature'] > 80) & (data['Vibration'] > 7)\n",
        "data.loc[failure_condition, 'Failure_Indicator'] = 1\n",
        "\n",
        "print(\"--- SYNTHETIC DATA CREATED ---\")\n",
        "print(f\"Total instances: {N_SAMPLES}\")\n",
        "print(f\"Failure instances (1): {data['Failure_Indicator'].sum()}\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = data[['Temperature', 'Vibration', 'Pressure']]\n",
        "y = data['Failure_Indicator']\n",
        "\n",
        "# Split the data into training and testing sets [1].\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# --- STEP 3: TRAIN THE RANDOM FOREST MODEL --- [1]\n",
        "# Ensemble methods use a team of models [3, 4]. Random Forest is a classic bagging method [5].\n",
        "\n",
        "# Import the Random Forest Classifier [2].\n",
        "# We create our model, telling it we want a team of 50 decision trees (n_estimators=50) [2].\n",
        "# The collective intelligence of many models creates a much stronger conclusion [4].\n",
        "model = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "\n",
        "# This line, model.fit, tells our team of detectives (the 50 trees) to study the evidence (X_train)\n",
        "# and learn the patterns (y_train) [2].\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# --- STEP 4: TEST THE MODEL --- [1]\n",
        "# Predict on the test data to see if it learned the pattern correctly [1].\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Calculate and display the accuracy [6].\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "\n",
        "print(f\"Model Training Status: COMPLETE\")\n",
        "print(f\"Accuracy on Test Data: {accuracy:.4f} (The sources show high accuracy, around 95%, is typical for these models [6])\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# --- INSIGHTS ---\n",
        "# This exercise shows how an ensemble automatically figures out complex relationships,\n",
        "# such as the rule we made up about high temp plus high vibration [2].\n",
        "# Ensembles are powerful masters at finding tricky nonlinear patterns [7].\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4oNevzTenZf",
        "outputId": "775490d6-186b-45ab-9746-a968d801dbf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Synthetic Data Generated ---\n",
            "Total instances of failure pattern found: 14\n",
            "------------------------------\n",
            "Model Training Status: COMPLETE\n",
            "Accuracy on Test Data: 0.9867\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries. Scikit-learn is essential for implementing ensemble methods.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "# We import the Random Forest Classifier, which is the recommended ensemble model [1, 2].\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# --- STEP 1: MAKE UP SOME FAKE SENSOR DATA ---\n",
        "# Simulate constant streaming data from machinery: Temperature, vibration, pressure [5].\n",
        "N_SAMPLES = 1000\n",
        "\n",
        "# Create synthetic data points for features\n",
        "temperature = np.random.normal(loc=70, scale=8, size=N_SAMPLES)\n",
        "vibration = np.random.normal(loc=5, scale=2, size=N_SAMPLES)\n",
        "pressure = np.random.normal(loc=100, scale=10, size=N_SAMPLES)\n",
        "\n",
        "# Combine the sensor data into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'Temperature': temperature,\n",
        "    'Vibration': vibration,\n",
        "    'Pressure': pressure\n",
        "})\n",
        "\n",
        "# --- STEP 2: CREATE A SIMPLE RULE FOR FAILURE (THE 'FINGERPRINT') ---\n",
        "# A failure leaves a complex, non-linear pattern or \"fingerprint\" in the data [4, 5].\n",
        "# We define a failure rule (1) as high temp (e.g., > 80) AND high vibration (e.g., > 7).\n",
        "\n",
        "# Initialize the target variable (0 = No Failure, 1 = Failure)\n",
        "data['Failure_Indicator'] = 0\n",
        "\n",
        "# Apply the failure rule (the pattern the ensemble model must learn)\n",
        "failure_condition = (data['Temperature'] > 80) & (data['Vibration'] > 7)\n",
        "data.loc[failure_condition, 'Failure_Indicator'] = 1 # Set the indicator to 1 for instances matching the fingerprint\n",
        "\n",
        "print(\"--- Synthetic Data Generated ---\")\n",
        "print(f\"Total instances of failure pattern found: {data['Failure_Indicator'].sum()}\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = data[['Temperature', 'Vibration', 'Pressure']]\n",
        "y = data['Failure_Indicator']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# --- STEP 3: TRAIN THE RANDOM FOREST ENSEMBLE MODEL ---\n",
        "# Random Forest uses a democratic election approach (bagging) [3].\n",
        "\n",
        "# Create the model, telling it \"we want a team of 50 decision trees\" (n_estimators=50) [1].\n",
        "model = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "\n",
        "# The crucial training step: 'model.fit'. This tells the team of detectives to\n",
        "# \"go study the evidence and learn the patterns\" [1].\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# --- STEP 4: TEST THE MODEL ---\n",
        "# Test the model on unseen data to ensure it learned the pattern correctly [1].\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Calculate and display the accuracy of the predictions.\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "\n",
        "print(f\"Model Training Status: COMPLETE\")\n",
        "print(f\"Accuracy on Test Data: {accuracy:.4f}\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# The ensemble method automatically figures out complex relationships like the rule\n",
        "# we made up about high temp plus high vibration [1]."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOBVWYAs7BZVefUCvONkHjH",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
